# ğŸ  DataHut-DuckHouse

**DataHut-DuckHouse** est une plateforme analytique lÃ©gÃ¨re, hybride et open source qui combine la simplicitÃ© de **DuckDB**, la scalabilitÃ© d'**Iceberg**, la rapiditÃ© d'**Arrow Flight** et la modularitÃ© de **dbt** pour crÃ©er un data stack moderne, local ou cloud-ready.

## Architecture

```
             +------------------------+
             |  CSV / Fichiers locaux |
             +-----------+------------+
                         |
                         v
             +------------------------+
             |    Client Arrow Flight |
             |  (ingest_flight.py)    |
             +-----------+------------+
                         |
                         v
          +--------------+---------------+
          |     Serveur Arrow Flight     |
          |        (app.py)              |
          | - stocke dans DuckDB         |
          | - crÃ©e vues ou tables        |
          +--------------+---------------+
                         |
            +------------+-----------+
            |        DuckDB          |
            |   (fichier .duckdb)    |
            +------------+-----------+
                         |
                         v
                  +-------------+
                  |     dbt     |
                  | Transformations |
                  +-------------+
```

## FonctionnalitÃ©s

- ğŸ”— Ingestion de donnÃ©es via Arrow Flight
- ğŸ¤ Stockage hybride avec **DuckDB** (et Iceberg Ã  venir)
- ğŸ“Š Transformations SQL dÃ©claratives avec **dbt**
- ğŸ“¦ Environnement reproductible avec **Poetry**
- â˜ï¸ Compatible avec S3/MinIO pour le stockage objet

## âš™ï¸ PrÃ©requis

- [Python 3.11](https://www.python.org/downloads/)
- [Poetry](https://python-poetry.org/docs/)
- [Docker](https://www.docker.com/)
- [dbt CLI](https://docs.getdbt.com/dbt-cli/installation)

## Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/ton-utilisateur/datahut-duckhouse.git
cd datahut-duckhouse
```

### 2. Installer les dÃ©pendances

```bash
poetry install
```

### 3. Lancer les services (MinIO + Flight Server)

```bash
docker-compose up --build
```

### 4. Ingestion de donnÃ©es

Placer un fichier CSV dans `ingestion/data/data.csv`, puis :

```bash
poetry run python scripts/ingest_flight.py
```

## Structure du projet

```
datahut-duckhouse/
â”œâ”€â”€ flight_server/       # Serveur Arrow Flight avec backend DuckDB
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ ingestion/           # DonnÃ©es sources
â”‚   â””â”€â”€ data/
â”œâ”€â”€ scripts/             # Scripts Python (ingestion, requÃªtes)
â”‚   â”œâ”€â”€ ingest_flight.py
â”‚   â””â”€â”€ query_duckdb.py
â”œâ”€â”€ transform/           # Projet dbt
â”‚   â””â”€â”€ dbt_project/
â”œâ”€â”€ config/              # Fichier de configuration dbt
â”‚   â””â”€â”€ dbt_profiles.yml
â”œâ”€â”€ .env                 # Variables dâ€™environnement
â”œâ”€â”€ pyproject.toml       # DÃ©pendances Poetry
â””â”€â”€ docker-compose.yml   # Conteneurs MinIO + Flight
```

## ğŸ§  Utilisation de dbt

```bash
export DBT_PROFILES_DIR=transform/dbt_project/config
cd transform/dbt_project
poetry run dbt run
```

## Exemple de requÃªte locale

```bash
poetry run python scripts/query_duckdb.py
```

## Prochaines amÃ©liorations

- â„ï¸ IntÃ©gration du backend Iceberg
- ğŸ§ª Ajout de tests dbt (`dbt test`)
- ğŸ“ˆ Dashboards interactifs avec DuckDB + Observable ou Streamlit
- â˜ï¸ IntÃ©gration BigQuery / Snowflake via Arrow Flight

## Licence

Ce projet est sous licence MIT.

## Auteur

Geovany Batista Polo LAGUERRE â€“ lgeobatpo98@gmail.com  
Data Science & Analytics Engineer
