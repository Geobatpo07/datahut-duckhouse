# ğŸ  DataHut-DuckHouse

**DataHut-DuckHouse** est une plateforme analytique lÃ©gÃ¨re, hybride et open source qui combine la simplicitÃ© de **DuckDB**, la scalabilitÃ© d'**Iceberg**, la rapiditÃ© d'**Arrow Flight**, lâ€™orchestration de **Xorq** et la modularitÃ© de **dbt** pour crÃ©er un data stack moderne, local ou cloud-ready.

## ğŸ§± Architecture SaaS hybride

```
             +------------------------+
             |  CSV / Fichiers locaux |
             +-----------+------------+
                         |
                         v
             +------------------------+
             |    Client Arrow Flight |
             |  (ingest_flight.py)    |
             +-----------+------------+
                         |
                         v
          +--------------+---------------+
          |     Serveur Arrow Flight     |
          |        (Xorq + app.py)       |
          | - backend hybride Iceberg + DuckDB
          | - snapshots, vues synchronisÃ©es
          +--------------+---------------+
                         |
         +---------------+----------------+
         |                                  |
     +--------+                       +-------------+
     | DuckDB |                       |   Iceberg   |
     +--------+                       +-------------+
         |                                  |
         +--------+         +---------------+
                  |         |
               +-------------+        +-------------+
               |     dbt     |        |    Trino    |
               +-------------+        +-------------+
                    |                      |
                    |                      v
                    |              outils BI (Metabase, Tableau)
                    |
                    v
             modÃ¨les SQL par tenant
```

## âœ¨ FonctionnalitÃ©s

- ğŸ”— Ingestion rapide via Arrow Flight
- ğŸ¤ Stockage hybride : **DuckDB** local & **Iceberg** (MinIO)
- ğŸ§  Orchestration via **Xorq** (Flight + backends multiples)
- ğŸ”„ Synchronisation automatique avec Trino (catalogues)
- ğŸ“Š Transformations SQL dÃ©claratives avec **dbt**
- ğŸ“¦ Multi-tenant : crÃ©ation/suppression dynamique
- â˜ï¸ IntÃ©gration S3 via MinIO

## âš™ï¸ PrÃ©requis

- [Python 3.11+](https://www.python.org/downloads/)
- [Poetry](https://python-poetry.org/docs/)
- [Docker](https://www.docker.com/)
- [dbt CLI](https://docs.getdbt.com/dbt-cli/installation)

## ğŸš€ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/Geobatpo07/datahut-duckhouse.git
cd datahut-duckhouse
```

### 2. Installer les dÃ©pendances Python

```bash
poetry install
```

### 3. Lancer lâ€™environnement complet

```bash
docker-compose up --build
```

### 4. CrÃ©er un tenant

```bash
poetry run python scripts/create_tenant.py --id tenant_acme
```

### 5. Ingestion de donnÃ©es

Placer un CSV dans `ingestion/data/data.csv` puis :

```bash
poetry run python scripts/ingest_flight.py
```

## ğŸ“‚ Structure du projet

```
datahut-duckhouse/
â”œâ”€â”€ flight_server/        # Serveur Arrow Flight + HybridBackend
|   â”œâ”€â”€ app/
â”‚      â”œâ”€â”€ app.py
|      â”œâ”€â”€ app_xorq.py
â”‚      â”œâ”€â”€ xorq_config.py
â”‚      â”œâ”€â”€ utils.py
â”‚      â””â”€â”€ backends/hybrid_backend.py
â”œâ”€â”€ ingestion/data/       # DonnÃ©es sources
â”œâ”€â”€ scripts/              # Ingestion, requÃªtes, gestion tenants
â”‚   â”œâ”€â”€ ingest_flight.py
â”‚   â”œâ”€â”€ query_duckdb.py
â”‚   â”œâ”€â”€ create_tenant.py
â”‚   â””â”€â”€ delete_tenant.py
â”œâ”€â”€ transform/dbt_project/ # ModÃ¨les dbt
â”œâ”€â”€ config/               # Trino, dbt, tenants, users
â”‚   â”œâ”€â”€ trino/etc/
â”‚   â”œâ”€â”€ tenants/
â”‚   â””â”€â”€ users/users.yamlx
â”œâ”€â”€ .env                  # Variables dâ€™environnement
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ pyproject.toml
```

## ğŸ§  Utiliser dbt avec DuckDB

```bash
export DBT_PROFILES_DIR=transform/dbt_project/config
cd transform/dbt_project
poetry run dbt run
```

## ğŸ” Exemple de requÃªte locale

```bash
poetry run python scripts/query_duckdb.py
```

## ğŸ”’ Suppression dâ€™un tenant

```bash
poetry run python scripts/delete_tenant.py --id tenant_acme
```

## ğŸ“ˆ Interface BI avec Trino

AccÃ©der Ã  Trino : [http://localhost:8080](http://localhost:8080)  
Utiliser `tenant_acme` comme catalogue Trino dans Superset ou Metabase.

## ğŸ›£ï¸ Roadmap

- âœ… Multi-tenant Iceberg + DuckDB
- âœ… Enregistrement dynamique Xorq + Trino
- ğŸ”œ Interface Flask/React de gestion
- ğŸ”œ Authentification + rÃ´les utilisateurs
- ğŸ”œ IntÃ©gration Metabase ou Superset
- ğŸ”œ DÃ©ploiement SaaS sur cloud public

## ğŸ“„ Licence

Projet sous licence MIT.

## âœï¸ Auteur

Geovany Batista Polo LAGUERRE â€“ [lgeobatpo98@gmail.com](mailto:lgeobatpo98@gmail.com) | Data Science & Analytics Engineer
